{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project for Wikishop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online store \"Wikishop\" launches a new service. Now users can edit and supplement product descriptions, just like in wiki communities. That is, clients propose their edits and comment on the changes of others. The store needs a tool that will look for toxic comments and submit them for moderation.\n",
    "\n",
    "Train the model to classify comments into positive and negative. At your disposal is a dataset with markup on the toxicity of edits.\n",
    "\n",
    "Build a model with a quality metric *F1* of at least 0.75.\n",
    "\n",
    "**Instructions for the implementation of the project**\n",
    "\n",
    "1. Download and prepare data.\n",
    "2. Train different models.\n",
    "3. Make conclusions.\n",
    "\n",
    "\n",
    "**Data Description**\n",
    "\n",
    "The data is in the `toxic_comments.csv` file. The *text* column contains the text of the comment and *toxic* is the target attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# !pip install fast_ml\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\leint\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\leint\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\leint\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\leint\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "# m = Mystem()\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('toxic_comments.csv', index_col='Unnamed: 0')\n",
    "data.head()\n",
    "m = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i cant make any real suggestions on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  daww he matches this background colour im seem...      0\n",
       "2  hey man im really not trying to edit war its j...      0\n",
       "3  more i cant make any real suggestions on impro...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to clean the text from extra characters\n",
    "def reg_data(row):\n",
    "    row = re.sub(r\"(?:\\n|\\r)\", \" \", row)\n",
    "    row = re.sub(r\"[^a-zA-Z ]+\", \"\", row).strip() # strip whitespace left and right with strip\n",
    "    row = row.lower()                             # lower case\n",
    "    return row\n",
    "\n",
    "data['text'] = data['text'].apply(reg_data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159292.000000\n",
       "mean        0.101612\n",
       "std         0.302139\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessed:\n",
    "\n",
    "- Loaded the main libraries;\n",
    "- the text is cleared of extra characters and the case is lowered;\n",
    "- data is separated for training;\n",
    "- data is lemmatized;\n",
    "- evaluated by TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset into samples\n",
    "\n",
    "train_features, target_train, features_valid, target_valid, features_test, target_test = train_valid_test_split(data, \n",
    "                                                                                                        target = 'toxic', \n",
    "                                                                                                        train_size=0.6, \n",
    "                                                                                                        valid_size=0.2, \n",
    "                                                                                                        test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a text corpus and lemmatization function\n",
    "\n",
    "train_corpus = train_features['text'].values\n",
    "\n",
    "def lemmatize(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    return ' '.join([m.lemmatize(i) for i in word_list])\n",
    "\n",
    "train_corpus[0] = lemmatize(train_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords, ngram_range=(1,1)) # stopword list \n",
    "tf_idf_train = count_tf_idf.fit_transform(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_corpus = features_valid['text'].values\n",
    "valid_corpus[0] = lemmatize(valid_corpus[0])\n",
    "tf_idf_valid = count_tf_idf.transform(valid_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['well fuckhead seemed a little over the top',\n",
       "       'scarborough nicknames   while i dont really want to expand on this section there are in fact some web references to scompton  you know youre from scarborugh when busta rules  there is also a wikipedia page called canadian slang which references scompton as well as a couple of other nicknames not mentioned in the scarborough article i used clusty search engine to find these references up to you whether you want to put this reference back i dont care one way or the other  regards    youre absolutely correct  serves me right for editing before my first cup of coffee in the morning  i found nothing relevant for scompton but when i redid the search later i did get results thru a search for scompton and scarborough i ought not to have deleted the entry based on a google search turning up nothingpersonally i generally dont see any value in having a section for nicknames for the municipality  but there is obviously precedent for having it eg toronto  the problem i have with these sections is that they end up including obvious entries like hogtown for toronto but then also up end up including nicknames that may be used in some circles but dont have particularly wide usage  the particular problem here in the scarborough article is that so many of the nicknames have such a negative connotation  perhaps thats just a reflection of public perception but i do believe that it does to a degree give the reader the wrong impression of the place  frankly i am just waiting for someone to add scandahar to the list im not from scarborough so i will leave the list in the hands of folks who have a better sense of whether its inclusion is justified  given your edits to the article you are probably better placed to make that call than i cheers',\n",
       "       'as your own comment indicates few jewish scholars have explored or developed a theology of the new covenant the new covenant is simply not an issue in jewish messianism as such  when that bit of jeremiah is discussed in jewish dialogue it is never as far as i know with the nomenclature new covenant  even if it is true that that is the appropriate term and that it is an important issue in jewish messianism in the absence of serious citation otherwise it would seem to me to be original research  neither the term nor the link to the article therefore have a place in an article on jewish messanism except as a compare and contrast with the christian notions  by the way keeping in mind that wikipedia is not a forum you are mistaken about converts to judaism  see our article on the topic',\n",
       "       ...,\n",
       "       'it is more like communism   of feminist groups are puppets to the gender feminist and  are puppets to or allies of the separatist feminist just as  of communist states where puppets to russia and  where puppets or allies to china the remaining  hate men casually regardless of who they are or what they do while the other  hate men with a passion no matter who they are or what they do so the article needs more detail because a majority of antifeminist dont hate feminism because they believe women are inferior but hate them because they know that feminism is in reality a hate supremacist group',\n",
       "       'templatennwarn',\n",
       "       'please stop your disruptive editing such as the edit you made to jonathan edwards theologian if your vandalism continues you will be blocked from editing wikipedia   t c  hows my driving'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus = features_test['text'].values\n",
    "test_corpus[0] = lemmatize(test_corpus[0])\n",
    "tf_idf_test = count_tf_idf.transform(test_corpus)\n",
    "test_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model training:**\n",
    "    \n",
    "- Logistic regression;\n",
    "- Logistic regression with cross-validation;\n",
    "- Decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score 0.7079377136346372\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "model_lr = LogisticRegression(random_state=12345)\n",
    "model_lr.fit(tf_idf_train, target_train)\n",
    "model_lr_answer = model_lr.predict(tf_idf_valid)\n",
    "f1_score_lr = f1_score(target_valid, model_lr_answer)\n",
    "print (\"f1_score\", f1_score_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'C': 3, 'penalty': 'l1'}\n",
      "Best Score 0.7705894922938182\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with cross-validation\n",
    "LogisticRegression = LogisticRegression(random_state=1, solver='liblinear', max_iter=100)\n",
    "params = {\n",
    "   'penalty':['l1'],        \n",
    "   'C':list(range(1,5)) \n",
    "}\n",
    "LR = GridSearchCV(LogisticRegression, params, cv=4, scoring='f1').fit(tf_idf_train, target_train)\n",
    "print (\"Best Params\", LR.best_params_)\n",
    "print (\"Best Score\", LR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score 0.5728073856483423\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "tree_model = DecisionTreeClassifier(random_state = 12345, max_depth=10)\n",
    "tree_model.fit(tf_idf_train, target_train)\n",
    "tree_model_answer = tree_model.predict(tf_idf_valid)\n",
    "tree_model_f1_score = f1_score(target_valid, tree_model_answer)\n",
    "print (\"f1_score\", tree_model_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score of best model 0.7871162556618017\n"
     ]
    }
   ],
   "source": [
    "# The best model is logistic regression. Let's check it on a test sample\n",
    "best = LR.predict(tf_idf_test)      \n",
    "f1_lr = f1_score(target_test, best)     \n",
    "print (\"f1_score of best model\", f1_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models trained:\n",
    "    \n",
    "- Logistic regression;\n",
    "- Logistic regression with cross-validation;\n",
    "- Decision tree.\n",
    "    \n",
    "Logistic regression with cross-validation turned out to be the best. She showed f1 = 0.76 on the validation set. On the test sample 0.78. The mark of 0.75 has been overcome."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 353,
    "start_time": "2022-10-08T07:47:23.035Z"
   },
   {
    "duration": 3134,
    "start_time": "2022-10-08T07:47:34.239Z"
   },
   {
    "duration": 18,
    "start_time": "2022-10-08T07:47:40.027Z"
   },
   {
    "duration": 668,
    "start_time": "2022-10-08T07:48:10.080Z"
   },
   {
    "duration": 2,
    "start_time": "2022-10-08T07:49:16.230Z"
   },
   {
    "duration": 2373,
    "start_time": "2022-10-08T07:53:15.150Z"
   },
   {
    "duration": 1584,
    "start_time": "2022-10-08T07:53:24.065Z"
   },
   {
    "duration": 1625,
    "start_time": "2022-10-08T07:53:32.116Z"
   },
   {
    "duration": 565,
    "start_time": "2022-10-08T07:58:28.671Z"
   },
   {
    "duration": 719,
    "start_time": "2022-10-08T07:58:36.481Z"
   },
   {
    "duration": 728,
    "start_time": "2022-10-08T07:58:40.340Z"
   },
   {
    "duration": 1554,
    "start_time": "2022-10-08T08:18:19.088Z"
   },
   {
    "duration": 799,
    "start_time": "2022-10-08T08:20:32.678Z"
   },
   {
    "duration": 7401,
    "start_time": "2022-10-08T08:20:59.798Z"
   },
   {
    "duration": 118,
    "start_time": "2022-10-08T08:21:16.364Z"
   },
   {
    "duration": 716,
    "start_time": "2022-10-08T08:21:20.445Z"
   },
   {
    "duration": 1004,
    "start_time": "2022-10-08T08:21:22.753Z"
   },
   {
    "duration": 834,
    "start_time": "2022-10-08T08:21:37.473Z"
   },
   {
    "duration": 725,
    "start_time": "2022-10-08T08:21:43.075Z"
   },
   {
    "duration": 906,
    "start_time": "2022-10-08T08:21:44.895Z"
   },
   {
    "duration": 680,
    "start_time": "2022-10-08T08:21:59.968Z"
   },
   {
    "duration": 1699,
    "start_time": "2022-10-08T08:22:03.851Z"
   },
   {
    "duration": 442,
    "start_time": "2022-10-08T08:24:06.703Z"
   },
   {
    "duration": 792,
    "start_time": "2022-10-08T08:24:07.147Z"
   },
   {
    "duration": 2299,
    "start_time": "2022-10-08T08:24:07.941Z"
   },
   {
    "duration": 30,
    "start_time": "2022-10-08T08:24:10.242Z"
   },
   {
    "duration": 19,
    "start_time": "2022-10-08T08:24:30.211Z"
   },
   {
    "duration": 2,
    "start_time": "2022-10-08T08:25:51.021Z"
   },
   {
    "duration": 685,
    "start_time": "2022-10-08T08:25:51.363Z"
   },
   {
    "duration": 2328,
    "start_time": "2022-10-08T08:25:56.173Z"
   },
   {
    "duration": 14,
    "start_time": "2022-10-08T08:26:00.438Z"
   },
   {
    "duration": 35,
    "start_time": "2022-10-08T08:26:05.846Z"
   },
   {
    "duration": 2871,
    "start_time": "2022-10-08T09:06:09.268Z"
   },
   {
    "duration": 1197,
    "start_time": "2022-10-08T09:06:13.473Z"
   },
   {
    "duration": 86,
    "start_time": "2022-10-08T09:07:02.286Z"
   },
   {
    "duration": 7,
    "start_time": "2022-10-08T09:07:08.836Z"
   },
   {
    "duration": 71,
    "start_time": "2022-10-08T09:10:06.570Z"
   },
   {
    "duration": 8,
    "start_time": "2022-10-08T09:10:12.697Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-08T09:10:18.141Z"
   },
   {
    "duration": 130,
    "start_time": "2022-10-08T09:11:05.290Z"
   },
   {
    "duration": 55,
    "start_time": "2022-10-08T09:11:25.589Z"
   },
   {
    "duration": 2117,
    "start_time": "2022-10-08T09:15:19.107Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-08T09:15:42.420Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-08T09:15:44.844Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-08T09:15:51.628Z"
   },
   {
    "duration": 757,
    "start_time": "2022-10-08T09:15:52.457Z"
   },
   {
    "duration": 1895,
    "start_time": "2022-10-08T09:16:27.786Z"
   },
   {
    "duration": 14,
    "start_time": "2022-10-08T09:17:04.000Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-08T09:17:06.245Z"
   },
   {
    "duration": 412,
    "start_time": "2022-10-08T09:17:23.760Z"
   },
   {
    "duration": 26,
    "start_time": "2022-10-08T09:17:27.530Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-08T09:17:34.988Z"
   },
   {
    "duration": 3226,
    "start_time": "2022-10-08T09:17:35.263Z"
   },
   {
    "duration": 2380,
    "start_time": "2022-10-08T09:17:38.492Z"
   },
   {
    "duration": 24,
    "start_time": "2022-10-08T09:17:40.873Z"
   },
   {
    "duration": 42,
    "start_time": "2022-10-08T09:17:40.900Z"
   },
   {
    "duration": 3035,
    "start_time": "2022-10-08T09:17:43.662Z"
   },
   {
    "duration": 6,
    "start_time": "2022-10-08T09:17:48.336Z"
   },
   {
    "duration": 11,
    "start_time": "2022-10-08T09:17:56.327Z"
   },
   {
    "duration": 91,
    "start_time": "2022-10-08T09:18:09.900Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-08T09:18:13.506Z"
   },
   {
    "duration": 23,
    "start_time": "2022-10-08T09:21:24.899Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-08T09:22:41.960Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-08T09:51:23.067Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-08T09:51:29.296Z"
   },
   {
    "duration": 11,
    "start_time": "2022-10-08T09:51:34.863Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-08T09:51:57.556Z"
   },
   {
    "duration": 12,
    "start_time": "2022-10-08T09:52:02.650Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-08T09:52:28.625Z"
   },
   {
    "duration": 9155,
    "start_time": "2022-10-08T09:52:34.035Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-08T09:52:55.412Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-08T11:27:17.428Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-08T11:27:48.363Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-08T11:28:01.004Z"
   },
   {
    "duration": 231,
    "start_time": "2022-10-08T11:28:22.206Z"
   },
   {
    "duration": 729,
    "start_time": "2022-10-08T11:28:23.322Z"
   },
   {
    "duration": 49,
    "start_time": "2022-10-08T11:29:26.025Z"
   },
   {
    "duration": 1897,
    "start_time": "2022-10-08T11:29:32.296Z"
   },
   {
    "duration": 1937,
    "start_time": "2022-10-08T11:29:34.195Z"
   },
   {
    "duration": 3116,
    "start_time": "2022-10-08T11:29:36.134Z"
   },
   {
    "duration": 2167,
    "start_time": "2022-10-08T11:29:39.251Z"
   },
   {
    "duration": 14,
    "start_time": "2022-10-08T11:29:41.420Z"
   },
   {
    "duration": 29,
    "start_time": "2022-10-08T11:29:41.436Z"
   },
   {
    "duration": 2834,
    "start_time": "2022-10-08T11:29:41.467Z"
   },
   {
    "duration": 11,
    "start_time": "2022-10-08T11:29:44.303Z"
   },
   {
    "duration": 82,
    "start_time": "2022-10-08T11:29:44.316Z"
   },
   {
    "duration": 8473,
    "start_time": "2022-10-08T11:29:44.400Z"
   },
   {
    "duration": 50,
    "start_time": "2022-10-08T11:32:01.265Z"
   },
   {
    "duration": 1810,
    "start_time": "2022-10-08T11:32:17.536Z"
   },
   {
    "duration": 1939,
    "start_time": "2022-10-08T11:32:19.348Z"
   },
   {
    "duration": 3155,
    "start_time": "2022-10-08T11:32:21.289Z"
   },
   {
    "duration": 2428,
    "start_time": "2022-10-08T11:32:24.446Z"
   },
   {
    "duration": 22,
    "start_time": "2022-10-08T11:32:26.876Z"
   },
   {
    "duration": 31,
    "start_time": "2022-10-08T11:32:26.900Z"
   },
   {
    "duration": 72,
    "start_time": "2022-10-08T11:32:26.933Z"
   },
   {
    "duration": 2033,
    "start_time": "2022-10-08T11:32:27.007Z"
   },
   {
    "duration": 5174,
    "start_time": "2022-10-08T11:32:29.043Z"
   },
   {
    "duration": 415,
    "start_time": "2022-10-08T11:32:34.219Z"
   },
   {
    "duration": 1649,
    "start_time": "2022-10-08T11:32:51.580Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-08T11:32:56.043Z"
   },
   {
    "duration": 1631,
    "start_time": "2022-10-08T11:33:01.005Z"
   },
   {
    "duration": 154,
    "start_time": "2022-10-08T11:33:46.610Z"
   },
   {
    "duration": 379,
    "start_time": "2022-10-08T11:33:58.153Z"
   },
   {
    "duration": 1637,
    "start_time": "2022-10-08T11:34:18.146Z"
   },
   {
    "duration": 1824,
    "start_time": "2022-10-08T11:34:53.979Z"
   },
   {
    "duration": 2011,
    "start_time": "2022-10-08T11:34:55.806Z"
   },
   {
    "duration": 3077,
    "start_time": "2022-10-08T11:34:57.821Z"
   },
   {
    "duration": 2259,
    "start_time": "2022-10-08T11:35:00.902Z"
   },
   {
    "duration": 14,
    "start_time": "2022-10-08T11:35:03.163Z"
   },
   {
    "duration": 45,
    "start_time": "2022-10-08T11:35:03.179Z"
   },
   {
    "duration": 55,
    "start_time": "2022-10-08T11:35:03.225Z"
   },
   {
    "duration": 2074,
    "start_time": "2022-10-08T11:35:03.281Z"
   },
   {
    "duration": 5459,
    "start_time": "2022-10-08T11:35:05.357Z"
   },
   {
    "duration": 2058,
    "start_time": "2022-10-08T11:35:10.818Z"
   },
   {
    "duration": 1948,
    "start_time": "2022-10-08T11:35:12.878Z"
   },
   {
    "duration": 1577,
    "start_time": "2022-10-08T11:35:14.827Z"
   },
   {
    "duration": 33,
    "start_time": "2022-10-08T11:38:05.558Z"
   },
   {
    "duration": 122,
    "start_time": "2022-10-08T11:38:28.748Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-08T11:38:43.585Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-08T11:38:48.506Z"
   },
   {
    "duration": 11,
    "start_time": "2022-10-08T11:39:00.613Z"
   },
   {
    "duration": 12,
    "start_time": "2022-10-08T11:39:07.890Z"
   },
   {
    "duration": 79207,
    "start_time": "2022-10-08T11:40:12.901Z"
   },
   {
    "duration": 20847,
    "start_time": "2022-10-08T11:41:33.750Z"
   },
   {
    "duration": 19,
    "start_time": "2022-10-08T11:48:52.050Z"
   },
   {
    "duration": 29114,
    "start_time": "2022-10-08T11:49:57.045Z"
   },
   {
    "duration": 1849,
    "start_time": "2022-10-08T11:50:30.253Z"
   },
   {
    "duration": 1870,
    "start_time": "2022-10-08T11:50:32.104Z"
   },
   {
    "duration": 757,
    "start_time": "2022-10-08T11:50:33.975Z"
   },
   {
    "duration": 2353,
    "start_time": "2022-10-08T11:50:34.733Z"
   },
   {
    "duration": 21,
    "start_time": "2022-10-08T11:50:37.088Z"
   },
   {
    "duration": 35,
    "start_time": "2022-10-08T11:50:37.111Z"
   },
   {
    "duration": 84,
    "start_time": "2022-10-08T11:50:37.148Z"
   },
   {
    "duration": 2036,
    "start_time": "2022-10-08T11:50:37.233Z"
   },
   {
    "duration": 5446,
    "start_time": "2022-10-08T11:50:39.271Z"
   },
   {
    "duration": 2218,
    "start_time": "2022-10-08T11:50:44.719Z"
   },
   {
    "duration": 2133,
    "start_time": "2022-10-08T11:50:46.939Z"
   },
   {
    "duration": 42622,
    "start_time": "2022-10-08T11:50:49.073Z"
   },
   {
    "duration": 124,
    "start_time": "2022-10-08T11:59:49.030Z"
   },
   {
    "duration": 36,
    "start_time": "2022-10-08T11:59:55.865Z"
   },
   {
    "duration": 1185785,
    "start_time": "2022-10-08T11:59:58.720Z"
   },
   {
    "duration": 110,
    "start_time": "2022-10-08T12:21:24.497Z"
   },
   {
    "duration": 7,
    "start_time": "2022-10-08T12:21:42.900Z"
   },
   {
    "duration": 77000,
    "start_time": "2022-10-08T12:21:46.192Z"
   },
   {
    "duration": 4254,
    "start_time": "2022-10-08T12:24:04.862Z"
   },
   {
    "duration": 134915,
    "start_time": "2022-10-08T12:26:59.211Z"
   },
   {
    "duration": 89,
    "start_time": "2022-10-08T12:30:41.292Z"
   },
   {
    "duration": 80,
    "start_time": "2022-10-08T12:31:04.442Z"
   },
   {
    "duration": 15206,
    "start_time": "2022-10-08T12:31:29.178Z"
   },
   {
    "duration": 4107,
    "start_time": "2022-10-08T12:32:05.530Z"
   },
   {
    "duration": 14340,
    "start_time": "2022-10-08T12:32:45.593Z"
   },
   {
    "duration": 16,
    "start_time": "2022-10-08T12:35:35.405Z"
   },
   {
    "duration": 153,
    "start_time": "2022-10-08T12:37:30.661Z"
   },
   {
    "duration": 130,
    "start_time": "2022-10-08T12:40:58.922Z"
   },
   {
    "duration": 1815,
    "start_time": "2022-10-08T12:43:22.834Z"
   },
   {
    "duration": 1734,
    "start_time": "2022-10-08T12:43:24.652Z"
   },
   {
    "duration": 809,
    "start_time": "2022-10-08T12:43:26.387Z"
   },
   {
    "duration": 2179,
    "start_time": "2022-10-08T12:43:27.197Z"
   },
   {
    "duration": 21,
    "start_time": "2022-10-08T12:43:29.378Z"
   },
   {
    "duration": 30,
    "start_time": "2022-10-08T12:43:29.401Z"
   },
   {
    "duration": 63,
    "start_time": "2022-10-08T12:43:29.432Z"
   },
   {
    "duration": 2068,
    "start_time": "2022-10-08T12:43:29.497Z"
   },
   {
    "duration": 5235,
    "start_time": "2022-10-08T12:43:31.567Z"
   },
   {
    "duration": 2023,
    "start_time": "2022-10-08T12:43:36.804Z"
   },
   {
    "duration": 1979,
    "start_time": "2022-10-08T12:43:38.829Z"
   },
   {
    "duration": 40602,
    "start_time": "2022-10-08T12:43:40.810Z"
   },
   {
    "duration": 15810,
    "start_time": "2022-10-08T12:44:21.413Z"
   },
   {
    "duration": 3910,
    "start_time": "2022-10-08T12:44:37.226Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-08T12:44:41.138Z"
   },
   {
    "duration": 43,
    "start_time": "2022-10-10T16:22:04.209Z"
   },
   {
    "duration": 2519,
    "start_time": "2022-10-10T16:22:35.533Z"
   },
   {
    "duration": 2869,
    "start_time": "2022-10-10T16:22:38.054Z"
   },
   {
    "duration": 2126,
    "start_time": "2022-10-10T16:22:40.924Z"
   },
   {
    "duration": 2265,
    "start_time": "2022-10-10T16:22:43.052Z"
   },
   {
    "duration": 17,
    "start_time": "2022-10-10T16:22:45.319Z"
   },
   {
    "duration": 31,
    "start_time": "2022-10-10T16:22:45.338Z"
   },
   {
    "duration": 98,
    "start_time": "2022-10-10T16:22:45.371Z"
   },
   {
    "duration": 1117,
    "start_time": "2022-10-10T16:22:48.207Z"
   },
   {
    "duration": 3828,
    "start_time": "2022-10-10T16:22:58.617Z"
   },
   {
    "duration": 1793,
    "start_time": "2022-10-10T16:23:11.834Z"
   },
   {
    "duration": 1751,
    "start_time": "2022-10-10T16:23:13.629Z"
   },
   {
    "duration": 708,
    "start_time": "2022-10-10T16:23:15.382Z"
   },
   {
    "duration": 2145,
    "start_time": "2022-10-10T16:23:16.092Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-10T16:23:18.238Z"
   },
   {
    "duration": 29,
    "start_time": "2022-10-10T16:23:18.254Z"
   },
   {
    "duration": 48,
    "start_time": "2022-10-10T16:23:18.301Z"
   },
   {
    "duration": 1108,
    "start_time": "2022-10-10T16:23:18.350Z"
   },
   {
    "duration": 3814,
    "start_time": "2022-10-10T16:23:19.459Z"
   },
   {
    "duration": 1175,
    "start_time": "2022-10-10T16:23:23.275Z"
   },
   {
    "duration": 1137,
    "start_time": "2022-10-10T16:23:24.452Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-10T16:23:25.591Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-10T16:23:25.602Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-10T16:23:25.603Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-10T16:23:25.604Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-10T16:25:11.422Z"
   },
   {
    "duration": 40185,
    "start_time": "2022-10-10T16:25:14.916Z"
   },
   {
    "duration": 17729,
    "start_time": "2022-10-10T16:25:55.103Z"
   },
   {
    "duration": 4719,
    "start_time": "2022-10-10T16:26:12.834Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-10T16:26:17.555Z"
   },
   {
    "duration": 2706,
    "start_time": "2022-10-16T12:19:02.371Z"
   },
   {
    "duration": 1956,
    "start_time": "2022-10-16T12:19:05.079Z"
   },
   {
    "duration": 2362,
    "start_time": "2022-10-16T12:19:07.037Z"
   },
   {
    "duration": 2393,
    "start_time": "2022-10-16T12:19:09.401Z"
   },
   {
    "duration": 20,
    "start_time": "2022-10-16T12:19:11.795Z"
   },
   {
    "duration": 24,
    "start_time": "2022-10-16T12:19:11.817Z"
   },
   {
    "duration": 47,
    "start_time": "2022-10-16T12:19:11.843Z"
   },
   {
    "duration": 1299,
    "start_time": "2022-10-16T12:19:13.488Z"
   },
   {
    "duration": 66,
    "start_time": "2022-10-16T12:20:49.583Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-16T12:20:55.357Z"
   },
   {
    "duration": 1929,
    "start_time": "2022-10-16T12:21:05.129Z"
   },
   {
    "duration": 1698,
    "start_time": "2022-10-16T12:21:07.060Z"
   },
   {
    "duration": 797,
    "start_time": "2022-10-16T12:21:08.759Z"
   },
   {
    "duration": 2355,
    "start_time": "2022-10-16T12:21:09.558Z"
   },
   {
    "duration": 14,
    "start_time": "2022-10-16T12:21:11.915Z"
   },
   {
    "duration": 20,
    "start_time": "2022-10-16T12:21:11.931Z"
   },
   {
    "duration": 61,
    "start_time": "2022-10-16T12:21:11.953Z"
   },
   {
    "duration": 1138,
    "start_time": "2022-10-16T12:21:12.016Z"
   },
   {
    "duration": 3893,
    "start_time": "2022-10-16T12:21:13.156Z"
   },
   {
    "duration": 1161,
    "start_time": "2022-10-16T12:21:17.052Z"
   },
   {
    "duration": 1165,
    "start_time": "2022-10-16T12:21:18.215Z"
   },
   {
    "duration": 37739,
    "start_time": "2022-10-16T12:21:19.381Z"
   },
   {
    "duration": 12744,
    "start_time": "2022-10-16T12:21:57.122Z"
   },
   {
    "duration": 3885,
    "start_time": "2022-10-16T12:22:09.868Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-16T12:22:13.755Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
